{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f86f72",
   "metadata": {},
   "source": [
    "# Tarea #1 Ciencia de Datos 2 Santiago Henao RendÃ³n \n",
    "## Pipeline de Procesamiento de Datos (Titanic)\n",
    "\n",
    "El objetivo de este trabajo es seleccionar un dataset, realizar un mini-EDA (AnÃ¡lisis Exploratorio de Datos) e implementar un Pipeline de Preprocesamiento robusto con scikit-learn.\n",
    "\n",
    "### Paso 1: Cargar librerÃ­as necesarias para el ejercicio.\n",
    "Comenzamos importando las librerÃ­as necesarias de Python (pandas para manejo de datos, y varios mÃ³dulos de scikit-learn para el pipeline y el modelado).\n",
    "\n",
    "Seleccionamos un subconjunto de 7 variables del dataset para cumplir con el requisito de tener entre 5 y 10 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22891f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del set de entrenamiento (X_train): (712, 6)\n"
     ]
    }
   ],
   "source": [
    "# ImportaciÃ³n de librerÃ­as esenciales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. Cargar el dataset 'train.csv'\n",
    "df_completo = pd.read_csv('train.csv')\n",
    "\n",
    "# 2. Seleccionar el subconjunto de columnas (Requisito: 5 a 10 variables)\n",
    "COLUMNAS_USAR = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Embarked']\n",
    "df = df_completo[COLUMNAS_USAR].copy()\n",
    "\n",
    "# Separar variables predictoras (X) y objetivo (y)\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "# Dividir para entrenamiento y prueba (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dimensiones del set de entrenamiento (X_train): {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c060451a",
   "metadata": {},
   "source": [
    "### Paso 2: Mini EDA y DefiniciÃ³n de Estrategias de Procesamiento\n",
    "Realizamos una breve exploraciÃ³n del set de entrenamiento para identificar los tipos de variables, datos faltantes y definir las estrategias de preprocesamiento.\n",
    "#### 2.1: EstadÃ­sticas Descriptivas e IdentificaciÃ³n de Datos Faltantes (N/A)\n",
    "Verificamos la cantidad de valores nulos por columna para determinar la estrategia de imputaciÃ³n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0724f11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EstadÃ­sticas Descriptivas de Variables NumÃ©ricas en X_train ---\n",
      "              Age       SibSp        Fare\n",
      "count  572.000000  712.000000  712.000000\n",
      "mean    29.498846    0.553371   32.586276\n",
      "std     14.500059    1.176404   51.969529\n",
      "min      0.420000    0.000000    0.000000\n",
      "25%     21.000000    0.000000    7.925000\n",
      "50%     28.000000    0.000000   14.454200\n",
      "75%     38.000000    1.000000   30.500000\n",
      "max     80.000000    8.000000  512.329200\n",
      "\n",
      "--- Frecuencia de CategorÃ­as y Faltantes en X_train ---\n",
      "\n",
      "--- Columna: Pclass ---\n",
      "Pclass\n",
      "3    398\n",
      "1    163\n",
      "2    151\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Columna: Sex ---\n",
      "Sex\n",
      "male      467\n",
      "female    245\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Columna: Embarked ---\n",
      "Embarked\n",
      "S      525\n",
      "C      125\n",
      "Q       60\n",
      "NaN      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- EstadÃ­sticas Descriptivas de Variables NumÃ©ricas en X_train ---\")\n",
    "print(X_train[['Age', 'SibSp', 'Fare']].describe())\n",
    "\n",
    "print(\"\\n--- Frecuencia de CategorÃ­as y Faltantes en X_train ---\")\n",
    "for col in ['Pclass', 'Sex', 'Embarked']:\n",
    "    print(f\"\\n--- Columna: {col} ---\")\n",
    "    print(X_train[col].value_counts(dropna=False)) # dropna=False incluye los NaNs en el conteo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4017e09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Conteo de Datos Faltantes (NaN) en X_train ---\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age         140\n",
      "SibSp         0\n",
      "Fare          0\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "\n",
      "--- Tipos de Datos de las Variables ---\n",
      "Pclass       object\n",
      "Sex          object\n",
      "Age         float64\n",
      "SibSp         int64\n",
      "Fare        float64\n",
      "Embarked     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train['Pclass'] = X_train['Pclass'].astype(str)\n",
    "X_test['Pclass'] = X_test['Pclass'].astype(str)\n",
    "\n",
    "# Y ajusta la definiciÃ³n de categories en el Pipeline:\n",
    "ordinal_categories = [['3', '2', '1']] \n",
    "# Ahora son strings.\n",
    "\n",
    "print(\"--- Conteo de Datos Faltantes (NaN) en X_train ---\")\n",
    "print(X_train.isnull().sum())\n",
    "print(\"\\n--- Tipos de Datos de las Variables ---\")\n",
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da3eab",
   "metadata": {},
   "source": [
    "#### Hallazgos Clave:\n",
    "- La variable Age contiene 140 datos faltantes, permitiendo adoptar una estrategia de imputaciÃ³n por la mediana.\n",
    "- La variable categÃ³rica de Embarked contiene 2 datos faltantes. Se adopta estrategia de imputaciÃ³n por la Moda.\n",
    "\n",
    "#### 2.2 Resumen de Estrategias de Preprocesamiento\n",
    "\n",
    "Esta tabla resume la identificaciÃ³n de datos faltantes, la estrategia para llenar esos vacÃ­os (**ImputaciÃ³n**), y la estrategia para normalizar el rango de valores (**Escalamiento/CodificaciÃ³n**) para todas las variables utilizadas en el pipeline.\n",
    "\n",
    "| Columna | Tipo de Variable | Datos Faltantes | Estrategia de ImputaciÃ³n | Estrategia de CodificaciÃ³n / Escalamiento | RazÃ³n de la Estrategia |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| **`Age`** | NumÃ©rica (Continua) | **147** | Mediana | **MinMaxScaler** | ImputaciÃ³n con **Mediana** por ser robusta a *outliers*. **MinMaxScaler** para normalizar el rango entre $[0, 1]$. |\n",
    "| **`SibSp`** | NumÃ©rica (Conteo) | 0 | N/A | **StandardScaler** | **StandardScaler** para estandarizar el set de datos ($\\mu=0, \\sigma=1$), Ãºtil para variables de conteo. |\n",
    "| **`Fare`** | NumÃ©rica (Continua) | 0 | N/A | **StandardScaler** | Estandariza la alta varianza y los valores extremos (outliers) de la tarifa. |\n",
    "| **`Sex`** | CategÃ³rica (Nominal) | 0 | N/A | **OneHotEncoder** | Variable sin orden, crea columnas binarias para evitar que el modelo interprete la etiqueta como magnitud. |\n",
    "| **`Embarked`** | CategÃ³rica (Nominal) | **2** | Moda | **OneHotEncoder** | ImputaciÃ³n por la **Moda** debido a la baja cantidad de nulos. Se codifica para convertir texto a formato numÃ©rico. |\n",
    "| **`Pclass`** | CategÃ³rica (Ordinal) | 0 | N/A | **OrdinalEncoder** | Variable con orden (1Âª > 2Âª > 3Âª clase). Se codifica con valores numÃ©ricos que respetan esta jerarquÃ­a. |\n",
    "\n",
    "### Paso 3: DiseÃ±o e ImplementaciÃ³n del Pipeline\n",
    "Construimos los pipelines individuales (secuencias de ImputaciÃ³n y Escalamiento/CodificaciÃ³n) y los combinamos en un solo ColumnTransformer.\n",
    "\n",
    "#### 3.1 CreaciÃ³n de Componentes Individuales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec64443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ðŸŒ² Pipeline para NumÃ©ricas (StandardScaler)\n",
    "num_std_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 2. ðŸŒ² Pipeline para Age (MinMaxScaler)\n",
    "age_minmax_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# 3. ðŸ·ï¸ Pipeline para Nominales (OneHotEncoder)\n",
    "nominal_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 4. ðŸ“ Pipeline para Ordinales (OrdinalEncoder)\n",
    "\n",
    "# DefiniciÃ³n del orden: De la peor clase ('3') a la mejor ('1')\n",
    "# NOTA: Deben ser strings, ya que convertimos la columna.\n",
    "# Es una lista de listas, donde cada lista interior es la columna.\n",
    "\n",
    "ordinal_categories = [['3', '2', '1']] \n",
    "\n",
    "\n",
    "ordinal_pipeline = OrdinalEncoder(categories=ordinal_categories) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386808ea",
   "metadata": {},
   "source": [
    "#### 3.2: CombinaciÃ³n con ColumnTransformer\n",
    "El ColumnTransformer dirige cada pipeline de transformaciÃ³n al grupo de columnas correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "455c3ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer definido.\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Aplica StandardScaler a SibSp y Fare\n",
    "        ('num_std', num_std_pipeline, ['SibSp', 'Fare']),\n",
    "        # Aplica MinMaxScaler a Age\n",
    "        ('age_minmax', age_minmax_pipeline, ['Age']),\n",
    "        # Aplica OneHotEncoder a Sex y Embarked\n",
    "        ('cat_nom', nominal_pipeline, ['Sex', 'Embarked']),\n",
    "        # Aplica OrdinalEncoder a Pclass\n",
    "        ('cat_ord', ordinal_pipeline, ['Pclass'])\n",
    "    ],\n",
    "    remainder='drop' # Ignora cualquier columna que no haya sido especificada.\n",
    ")\n",
    "\n",
    "print(\"ColumnTransformer definido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d1f5d",
   "metadata": {},
   "source": [
    "#### 3.3 Pipeline Completo y Entrenamiento\n",
    "El Pipeline final encadena el preprocesamiento con un modelo de RegresiÃ³n LogÃ­stica y entrena el modelo de forma eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9f3ceb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------\n",
      "âœ… Pipeline de Preprocesamiento y Modelo entrenado.\n",
      "PrecisiÃ³n del modelo en el set de prueba: 0.7989\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pipeline completo: Preprocesador -> Clasificador\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, solver='liblinear'))\n",
    "])\n",
    "\n",
    "# ðŸš€ Entrenar el Pipeline\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# EvaluaciÃ³n\n",
    "score = full_pipeline.score(X_test, y_test)\n",
    "\n",
    "print(\"\\n----------------------------------------------------\")\n",
    "print(\"âœ… Pipeline de Preprocesamiento y Modelo entrenado.\")\n",
    "print(f\"PrecisiÃ³n del modelo en el set de prueba: {score:.4f}\")\n",
    "print(\"----------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
